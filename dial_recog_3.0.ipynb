{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Paths: []\n",
      "Output Directory Base: .\n",
      "Frame Skip: 60\n",
      "Segment Threshold: 0.2\n",
      "Window Size: 400\n",
      "Step Angle: 2\n",
      "Frame Start: None\n",
      "Frame End: None\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 939\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame End:\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame_end)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m--> 939\u001b[0m \u001b[43mprocess_multiple_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_end\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 474\u001b[0m, in \u001b[0;36mprocess_multiple_videos\u001b[1;34m(video_paths, output_dir_base, frame_skip, segment_threshold, frame_start, frame_end)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# Ask the user how many dials are being used\u001b[39;00m\n\u001b[0;32m    473\u001b[0m num_dials \u001b[38;5;241m=\u001b[39m get_int_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many dials are being used? (1, 2, 3, ...): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 474\u001b[0m dial_letters \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m65\u001b[39m \u001b[38;5;241m+\u001b[39m i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_dials\u001b[49m\u001b[43m)\u001b[49m]  \u001b[38;5;66;03m# Generate dial letters ['A', 'B', 'C', ...]\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Ask the user for the configuration file path\u001b[39;00m\n\u001b[0;32m    477\u001b[0m config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the path of the config file (leave blank if not using a previous configuration): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import os\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "import math\n",
    "\n",
    "# Function to get integer input with error handling\n",
    "def get_int_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            input_value = input(prompt).strip()\n",
    "            return int(input_value) if input_value else None\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid integer.\")\n",
    "\n",
    "# Function to get float input with error handling\n",
    "def get_float_input(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return float(input(prompt))\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid float.\")\n",
    "\n",
    "# Class to handle segment processing and analysis\n",
    "class Segments:\n",
    "    def __init__(self, segment_boxes, base_values):\n",
    "        # Initialize the class with segment boxes and base values\n",
    "        self.flags = []  # List to store indices of flagged segments\n",
    "        self.segments = segment_boxes  # Store the bounding boxes for each segment\n",
    "        self.base_values = base_values  # Store base values associated with each segment\n",
    "        self.baseline_counts = []  # List to store baseline counts for background subtraction\n",
    "\n",
    "    # Function to analyze a given frame, detect segments, and flag the highest segment\n",
    "    def digest(self, number, segment_threshold, debug_file, frame_number, binary_threshold, write_to_debug=True, calculate_baseline=False):\n",
    "        self.flags = []  # Reset flags for each new frame\n",
    "        h, w = number.shape[:2]  # Get image dimensions (height and width)\n",
    "        all_segments = []  # List to store all segment details\n",
    "        segment_counts = []  # List to store non-zero pixel counts within each segment\n",
    "\n",
    "        if write_to_debug:\n",
    "            debug_file.write(f\"\\nFrame Number: {frame_number}\\n\")\n",
    "            debug_file.write(f\"Binary Threshold: {binary_threshold}\\n\")\n",
    "\n",
    "        for a in range(len(self.segments)):  # Loop through each segment\n",
    "            seg = self.segments[a]  # Get the current segment\n",
    "            rect = np.array([[seg[0], seg[4]], [seg[1], seg[5]], [seg[2], seg[6]], [seg[3], seg[7]]])  # Define the rectangle coordinates\n",
    "            rect[:, 0] = (rect[:, 0] * w).astype(int)  # Scale x-coordinates to image size\n",
    "            rect[:, 1] = (rect[:, 1] * h).astype(int)  # Scale y-coordinates to image size\n",
    "            mask = np.zeros_like(number)  # Create a mask of the same size as the image\n",
    "            cv2.fillPoly(mask, [rect.astype(int)], 255)  # Fill the mask with the segment shape\n",
    "            count = np.count_nonzero(mask & number)  # Count non-zero pixels in the segment\n",
    "            segment_counts.append((count, a))  # Append count and segment index to the list\n",
    "            all_segments.append((rect, a, count, np.count_nonzero(mask)))  # Store segment details\n",
    "\n",
    "        if write_to_debug:\n",
    "            debug_file.write(\"Raw Counts:\\n\")\n",
    "            for rect, a, count, area in all_segments:\n",
    "                debug_file.write(f\"Segment {a}: Count = {count}\\n\")\n",
    "\n",
    "        if calculate_baseline:  # If calculating baseline counts\n",
    "            self.baseline_counts = segment_counts.copy()  # Save the current counts as baseline\n",
    "\n",
    "        if segment_counts:  # If there are segments\n",
    "            highest_segment = max(segment_counts, key=lambda x: x[0])  # Find the segment with the highest count\n",
    "            self.flags.append(highest_segment[1])  # Flag the highest segment\n",
    "\n",
    "        # Loop through all segments and draw them on the image, highlighting flagged segments\n",
    "        for rect, a, count, area in all_segments:\n",
    "            color = (0, 0, 255) if a in self.flags else (255, 255, 255)  # Set color based on whether the segment is flagged\n",
    "            cv2.polylines(number, [rect.astype(int)], isClosed=True, color=color, thickness=2)  # Draw the segment on the image\n",
    "            value = self.base_values.get(a, 0)  # Get the base value for the segment\n",
    "            if a % 5 == 0:  # Display the value for every 5th segment\n",
    "                cv2.putText(number, f\"{value:.2f}\", (int(rect[0][0] + 50), int(rect[0][1])), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)  # Draw the value\n",
    "            if write_to_debug:\n",
    "                debug_file.write(f\"Segment {a}: Coordinates = {rect.tolist()}, Count = {count}, Area = {area}, Ratio = {count / area:.2f}\\n\")\n",
    "\n",
    "        if write_to_debug:  # Write final segment details to debug file\n",
    "            final_segment = self.flags[0] if self.flags else None\n",
    "            detected_number = self.get_num()  # Get the detected number\n",
    "            debug_file.write(f\"Flagged Segment: {final_segment}, Detected Number: {detected_number}\\n\")\n",
    "\n",
    "    # Function to get the detected number based on flagged segment\n",
    "    def get_num(self):\n",
    "        value = 0\n",
    "        if self.flags:\n",
    "            value = self.base_values.get(self.flags[0], 0)\n",
    "        return value\n",
    "\n",
    "# Function to remove red color from a frame\n",
    "def remove_red_color(frame):\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)  # Convert the frame from BGR to HSV color space\n",
    "\n",
    "    # Define the HSV range for purple to orange\n",
    "    # Part 1: Purple to red (130 to 180)\n",
    "    lower_purple_to_red = np.array([130, 50, 50])  # Lower bound for purple to red\n",
    "    upper_purple_to_red = np.array([180, 255, 255])  # Upper bound for purple to red\n",
    "\n",
    "    # Part 2: Red to orange (0 to 25)\n",
    "    lower_red_to_orange = np.array([0, 50, 50])  # Lower bound for red to orange\n",
    "    upper_red_to_orange = np.array([25, 255, 255])  # Upper bound for red to orange\n",
    "\n",
    "    # Create masks for both parts\n",
    "    mask_purple_to_red = cv2.inRange(hsv_frame, lower_purple_to_red, upper_purple_to_red)\n",
    "    mask_red_to_orange = cv2.inRange(hsv_frame, lower_red_to_orange, upper_red_to_orange)\n",
    "\n",
    "    # Combine both masks into a single mask\n",
    "    mask_combined = mask_purple_to_red | mask_red_to_orange\n",
    "\n",
    "    # Create a white image the same size as the original frame\n",
    "    white_frame = np.full_like(frame, 255)\n",
    "\n",
    "    # Replace the detected colors with white\n",
    "    frame_without_colors = cv2.bitwise_and(frame, frame, mask=cv2.bitwise_not(mask_combined))\n",
    "    frame_with_white = cv2.add(frame_without_colors, cv2.bitwise_and(white_frame, white_frame, mask=mask_combined))\n",
    "\n",
    "    return frame_with_white\n",
    "\n",
    "# Function to resize an image while maintaining aspect ratio\n",
    "def resize_image(image, width=None, height=None):\n",
    "    (h, w) = image.shape[:2]  # Get image dimensions (height and width)\n",
    "    if width is None and height is None:\n",
    "        return image  # Return original image if no dimensions are provided\n",
    "    if width is None:\n",
    "        ratio = height / float(h)  # Calculate the ratio for the given height\n",
    "        dim = (int(w * ratio), height)  # Calculate new dimensions\n",
    "    else:\n",
    "        ratio = width / float(w)  # Calculate the ratio for the given width\n",
    "        dim = (width, int(h * ratio))  # Calculate new dimensions\n",
    "    return cv2.resize(image, dim, interpolation=cv2.INTER_AREA)  # Resize the image with calculated dimensions\n",
    "\n",
    "# Function to handle mouse clicks on an image\n",
    "def get_mouse_click(image, window_name):\n",
    "    points = []\n",
    "\n",
    "    def click_event(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            cv2.circle(image, (x, y), 3, (255, 0, 0), -1)\n",
    "            cv2.imshow(window_name, image)\n",
    "            cv2.destroyAllWindows()  # Close the window after the first click\n",
    "\n",
    "    while True:\n",
    "        resized_image = resize_image(image, width=window_size)\n",
    "        resize_ratio_x = image.shape[1] / resized_image.shape[1]\n",
    "        resize_ratio_y = image.shape[0] / resized_image.shape[0]\n",
    "\n",
    "        cv2.imshow(window_name, resized_image)\n",
    "        cv2.setMouseCallback(window_name, click_event)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        if points:\n",
    "            # Convert the coordinates back to the original image size\n",
    "            original_point = (\n",
    "                int(points[0][0] * resize_ratio_x),\n",
    "                int(points[0][1] * resize_ratio_y)\n",
    "            )\n",
    "            return [original_point]  # Return a list containing the tuple\n",
    "\n",
    "        retry = input(\"No point selected. Would you like to select the point again? (y/n): \").strip().lower()\n",
    "        if retry != 'y':\n",
    "            cv2.destroyAllWindows()\n",
    "            return None\n",
    "\n",
    "# Function to select the center point of a dial\n",
    "def get_center_point(image, dial_name):\n",
    "    window_name = f'Select Center - Dial {dial_name}'\n",
    "    print(f\"Click to select the center of the dial {dial_name}.\")\n",
    "    while True:\n",
    "        resized_image = resize_image(image, width=window_size)\n",
    "        points = get_mouse_click(resized_image, window_name)\n",
    "        if points:\n",
    "            center = (int(points[0][0] * image.shape[1] / resized_image.shape[1]), int(points[0][1] * image.shape[0] / resized_image.shape[0]))\n",
    "            print(f\"Center selected: {center}\")\n",
    "            return center\n",
    "\n",
    "        retry = input(\"No point selected. Would you like to select the point again? (y/n): \").strip().lower()\n",
    "        if retry != 'y':\n",
    "            return None\n",
    "\n",
    "# Function to select the radius of a dial\n",
    "def get_radius(image, center, dial_name):\n",
    "    window_name = f'Select Radius - Dial {dial_name}'\n",
    "    print(f\"Click to select a point on the edge of the dial {dial_name} to define the radius.\")\n",
    "\n",
    "    while True:\n",
    "        # Get the edge point from the user click\n",
    "        edge_point = get_mouse_click(image.copy(), window_name)\n",
    "        if edge_point:\n",
    "            # Extract the actual point from the returned list\n",
    "            edge_point = edge_point[0]  # Unwrap the first point from the list\n",
    "            \n",
    "            # Calculate the radius based on the center and edge point\n",
    "            radius = int(np.sqrt((edge_point[0] - center[0])**2 + (edge_point[1] - center[1])**2))\n",
    "            print(f\"Radius selected: {radius}\")\n",
    "            return radius\n",
    "\n",
    "        retry = input(\"No point selected. Would you like to select the point again? (y/n): \").strip().lower()\n",
    "        if retry != 'y':\n",
    "            return None\n",
    "\n",
    "# Function to confirm the selected circle\n",
    "def confirm_circle(image, center, radius, dial_name):\n",
    "    while True:\n",
    "        preview_image = image.copy()\n",
    "        cv2.circle(preview_image, center, 5, (255, 0, 0), -1)\n",
    "        cv2.circle(preview_image, center, radius, (255, 0, 0), 2)\n",
    "        resized_preview_image = resize_image(preview_image, width=window_size)\n",
    "        cv2.imshow(f'Confirm Circle - Dial {dial_name}', resized_preview_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        if input(f\"Is the circle correct for dial {dial_name}? (y/n): \").strip().lower() != 'n':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "# Function to get angle from a click on an image\n",
    "def get_angle_from_click(image, center, window_name=\"Select Point\"):\n",
    "    # Display the image and get the click point from the user\n",
    "    print(\"Click on the point on the dial to select an angle.\")\n",
    "    \n",
    "    # Resize the image for display\n",
    "    resized_image = resize_image(image, width=window_size)\n",
    "    scale_x = image.shape[1] / resized_image.shape[1]\n",
    "    scale_y = image.shape[0] / resized_image.shape[0]\n",
    "\n",
    "    # Get the clicked point\n",
    "    points = get_mouse_click(resized_image, window_name)\n",
    "    \n",
    "    if not points:\n",
    "        print(\"No point selected. Please try again.\")\n",
    "        return None\n",
    "    \n",
    "    # Scale the point back to the original image size\n",
    "    point = (int(points[0][0] * scale_x), int(points[0][1] * scale_y))\n",
    "    \n",
    "    # Calculate the angle based on the center and the point\n",
    "    angle = np.degrees(np.arctan2(center[1] - point[1], point[0] - center[0]))\n",
    "    angle = (angle + 360) % 360\n",
    "    print(f\"Point selected: {point}, Angle: {angle:.2f}\")\n",
    "    return angle\n",
    "\n",
    "# Function to rotate a box around a center point\n",
    "def rotate_box(center, angle, box_size, image_shape):\n",
    "    angle_rad = np.deg2rad(angle)\n",
    "    rect = np.array([\n",
    "        [-box_size // 2, -box_size // 2],\n",
    "        [box_size // 2, -box_size // 2],\n",
    "        [box_size // 2, box_size // 2],\n",
    "        [-box_size // 2, box_size // 2]\n",
    "    ])\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "        [np.sin(angle_rad), np.cos(angle_rad)]\n",
    "    ])\n",
    "    rotated_rect = np.dot(rect, rotation_matrix) + center\n",
    "    rotated_rect[:, 0] = np.clip(rotated_rect[:, 0], 0, image_shape[1] - 1)\n",
    "    rotated_rect[:, 1] = np.clip(rotated_rect[:, 1], 0, image_shape[0] - 1)\n",
    "    return rotated_rect\n",
    "\n",
    "# Function to generate segment boxes\n",
    "def get_segment_boxes(image, center, radius_x, radius_y, origin_angle, max_angle, value_at_origin, value_at_max, clockwise=True):\n",
    "    # Normalize angles for the calculation\n",
    "    origin_angle = origin_angle % 360\n",
    "    max_angle = max_angle % 360\n",
    "    \n",
    "    # Determine angle range based on direction (clockwise or counterclockwise)\n",
    "    if clockwise:\n",
    "        if max_angle <= origin_angle:\n",
    "            max_angle += 360\n",
    "        angles = np.arange(origin_angle, max_angle, step_angle)\n",
    "    else:\n",
    "        if origin_angle <= max_angle:\n",
    "            origin_angle += 360\n",
    "        angles = np.arange(origin_angle, max_angle, -step_angle)\n",
    "\n",
    "    segment_boxes = []\n",
    "    box_size = int((min(radius_x, radius_y) * 2 * np.pi) / (360 / step_angle))\n",
    "\n",
    "    # Iterate through each angle to create the segment boxes\n",
    "    for angle in angles:\n",
    "        angle_rad = np.deg2rad(angle % 360)\n",
    "        x = center[0] + int(radius_x * np.cos(angle_rad))\n",
    "        y = center[1] - int(radius_y * np.sin(angle_rad))\n",
    "        rotated_rect = rotate_box([x, y], angle + 90, box_size, image.shape)\n",
    "        segment_boxes.append([\n",
    "            rotated_rect[0, 0] / image.shape[1], rotated_rect[1, 0] / image.shape[1], \n",
    "            rotated_rect[2, 0] / image.shape[1], rotated_rect[3, 0] / image.shape[1],\n",
    "            rotated_rect[0, 1] / image.shape[0], rotated_rect[1, 1] / image.shape[0], \n",
    "            rotated_rect[2, 1] / image.shape[0], rotated_rect[3, 1] / image.shape[0]\n",
    "        ])\n",
    "        cv2.polylines(image, [rotated_rect.astype(int)], isClosed=True, color=(255, 255, 255), thickness=3)\n",
    "\n",
    "    # Mapping values to segments based on angles\n",
    "    base_values = map_values_to_segments(segment_boxes, origin_angle, max_angle, value_at_origin, value_at_max, clockwise)\n",
    "    \n",
    "    # Annotate the image with segment values\n",
    "    for idx, segment in enumerate(segment_boxes):\n",
    "        if idx % 5 == 0:\n",
    "            rect = np.array([\n",
    "                [segment[0] * image.shape[1], segment[4] * image.shape[0]],\n",
    "                [segment[1] * image.shape[1], segment[5] * image.shape[0]],\n",
    "                [segment[2] * image.shape[1], segment[6] * image.shape[0]],\n",
    "                [segment[3] * image.shape[1], segment[7] * image.shape[0]],\n",
    "            ]).astype(int)\n",
    "            value = base_values.get(idx, 'N/A')\n",
    "            center_x = int((rect[0, 0] + rect[2, 0]) / 2)\n",
    "            center_y = int((rect[0, 1] + rect[2, 1]) / 2)\n",
    "            cv2.putText(image, f\"{value:.2f}\", (center_x, center_y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "\n",
    "    resized_image = resize_image(image, width=window_size)\n",
    "    cv2.imshow('Segment Boxes', resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return segment_boxes\n",
    "\n",
    "# Function to map values to segments\n",
    "def map_values_to_segments(segment_boxes, origin_angle, max_angle, value_at_origin, value_at_max, clockwise=True):\n",
    "    base_values = {}\n",
    "    num_segments = len(segment_boxes)\n",
    "    \n",
    "    # Calculate total angle span\n",
    "    if clockwise:\n",
    "        angle_span = (max_angle - origin_angle) % 360\n",
    "    else:\n",
    "        angle_span = (origin_angle - max_angle) % 360\n",
    "    \n",
    "    value_step = (value_at_max - value_at_origin) / (num_segments - 1) if num_segments > 1 else 0\n",
    "\n",
    "    current_value = value_at_origin\n",
    "    for j in range(num_segments):\n",
    "        base_values[j] = current_value\n",
    "        current_value += value_step\n",
    "\n",
    "    return base_values\n",
    "\n",
    "# Function to save configuration to a JSON file\n",
    "def save_config(segment_info_dict, config_path):\n",
    "    os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "    dict_to_save = {}\n",
    "    for dial_letter, segment_info in segment_info_dict.items():\n",
    "        (center, radius, radius_x, radius_y, origin_angle, max_angle, clockwise, segment_boxes, base_values) = segment_info\n",
    "        dict_to_save[dial_letter] = {\n",
    "            'center': center,\n",
    "            'radius': radius,\n",
    "            'radius_x': radius_x,\n",
    "            'radius_y': radius_y,\n",
    "            'origin_angle': origin_angle,\n",
    "            'max_angle': max_angle,\n",
    "            'clockwise': clockwise,\n",
    "            'segment_boxes': segment_boxes,\n",
    "            'base_values': base_values,\n",
    "        }\n",
    "\n",
    "    with open(config_path, 'w') as config_file:\n",
    "        json.dump(dict_to_save, config_file, indent=4)\n",
    "    print(f\"Configuration saved to {config_path}\")\n",
    "\n",
    "# Function to load configuration from a JSON file\n",
    "def load_config(config_path, video_paths):\n",
    "    config_path = normalize_path(config_path)\n",
    "    try:\n",
    "        with open(config_path, 'r') as config_file:\n",
    "            segment_info_dict = json.load(config_file)\n",
    "        print(\"Loaded configuration data successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load or parse the configuration file: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not video_paths:\n",
    "        print(\"No video paths provided.\")\n",
    "        return None\n",
    "\n",
    "    video_path = normalize_path(video_paths[0])\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video file {video_path}\")\n",
    "        return None\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to read the first frame from the video.\")\n",
    "        return None\n",
    "\n",
    "    for dial_letter, segment_info in segment_info_dict.items():\n",
    "        print(f\"Processing dial {dial_letter} with segment info: {segment_info}\")\n",
    "        if isinstance(segment_info, dict):\n",
    "            try:\n",
    "                center = tuple(int(x) for x in segment_info['center'])\n",
    "                radius = int(segment_info['radius'])\n",
    "                radius_x = int(segment_info['radius_x'])\n",
    "                radius_y = int(segment_info['radius_y'])\n",
    "                origin_angle = int(segment_info['origin_angle'])\n",
    "                max_angle = int(segment_info['max_angle'])\n",
    "                clockwise = segment_info['clockwise']\n",
    "                segment_boxes = [list(map(float, box)) for box in segment_info['segment_boxes']]\n",
    "\n",
    "                base_values = {int(k): round(float(v), 2) for k, v in segment_info['base_values'].items()}\n",
    "\n",
    "                segment_info_dict[dial_letter] = (center, radius, radius_x, radius_y, origin_angle, max_angle, clockwise, segment_boxes, base_values)\n",
    "\n",
    "                for idx, segment in enumerate(segment_boxes):\n",
    "                    rect = np.array([\n",
    "                        [segment[0] * frame.shape[1], segment[4] * frame.shape[0]],\n",
    "                        [segment[1] * frame.shape[1], segment[5] * frame.shape[0]],\n",
    "                        [segment[2] * frame.shape[1], segment[6] * frame.shape[0]],\n",
    "                        [segment[3] * frame.shape[1], segment[7] * frame.shape[0]],\n",
    "                    ]).astype(int)\n",
    "                    cv2.polylines(frame, [rect], isClosed=True, color=(255, 255, 255), thickness=2)\n",
    "                    if idx % 5 == 0:\n",
    "                        value = base_values.get(idx, 'N/A')\n",
    "                        cv2.putText(frame, f\"{value:.2f}\", (rect[0, 0] + 10, rect[0, 1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "                resized_frame = resize_image(frame, width=window_size)\n",
    "                cv2.imshow(f'Segment Preview for Dial {dial_letter}', resized_frame)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            except KeyError as e:\n",
    "                print(f\"Missing key in segment info for {dial_letter}: {e}\")\n",
    "            except TypeError as e:\n",
    "                print(f\"Type error in segment info for {dial_letter}: {e}\")\n",
    "        else:\n",
    "            print(f\"Error: Expected segment info for {dial_letter} to be a dictionary but got {type(segment_info)}\")\n",
    "\n",
    "    if input(\"Is the loaded config data correct? (y/n): \").strip().lower() != 'y':\n",
    "        print(\"Exiting due to incorrect config data.\")\n",
    "        return None\n",
    "\n",
    "    return segment_info_dict\n",
    "\n",
    "# Function to normalize file paths to ensure compatibility across different operating systems\n",
    "def normalize_path(path):\n",
    "    return os.path.normpath(path.strip('\"'))\n",
    "\n",
    "def get_replicate_info(dial_letters):\n",
    "    replicate_info = {}\n",
    "    has_replicates = input(\"Are there any replicates? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "    if not has_replicates:\n",
    "        return replicate_info\n",
    "\n",
    "    num_groups = get_int_input(\"How many groups of replicates are there? \")\n",
    "\n",
    "    for group_num in range(1, num_groups + 1):\n",
    "        num_replicates = get_int_input(f\"How many replicates are in group {group_num}? \")\n",
    "        while True:\n",
    "            dials = input(f\"Enter the dials for group {group_num} separated by spaces (e.g., A B C): \").strip().split()\n",
    "            dials = [dial.strip().upper() for dial in dials]\n",
    "\n",
    "            if all(dial in dial_letters for dial in dials) and len(dials) == num_replicates:\n",
    "                replicate_info[f'Group {group_num}'] = dials\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid input. Please ensure all dials are listed and the number matches the replicate count.\")\n",
    "\n",
    "    return replicate_info\n",
    "\n",
    "def process_multiple_videos(video_paths, output_dir_base, frame_skip, segment_threshold, frame_start, frame_end):\n",
    "    output_dir_base = normalize_path(output_dir_base)  # Normalize the base output directory path\n",
    "\n",
    "    combined_data = []  # List to store combined data from all videos\n",
    "\n",
    "    segment_info_dict = {}\n",
    "\n",
    "    # Ask the user how many dials are being used\n",
    "    num_dials = get_int_input(\"How many dials are being used? (1, 2, 3, ...): \")\n",
    "    dial_letters = [chr(65 + i) for i in range(num_dials)]  # Generate dial letters ['A', 'B', 'C', ...]\n",
    "\n",
    "    # Ask the user for the configuration file path\n",
    "    config_path = input(\"Enter the path of the config file (leave blank if not using a previous configuration): \").strip()\n",
    "    use_existing_config = bool(config_path)\n",
    "\n",
    "    if use_existing_config:\n",
    "        segment_info_dict = load_config(config_path, video_paths)\n",
    "        if segment_info_dict is None:\n",
    "            return\n",
    "    else:\n",
    "        # Manually set up the dials if not using an existing configuration\n",
    "        cap = cv2.VideoCapture(video_paths[0])\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_start or 0)\n",
    "        ret, unprocessed_frame = cap.read()\n",
    "        cap.release()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to read the first frame for segment configuration.\")\n",
    "            return\n",
    "\n",
    "        # Use the unprocessed first frame for configuration\n",
    "        for dial_letter in dial_letters:\n",
    "            print(f\"\\nSetting up for Dial {dial_letter}\")\n",
    "\n",
    "            while True:\n",
    "                # Select the center of the dial\n",
    "                center = get_center_point(unprocessed_frame.copy(), dial_letter)\n",
    "                if center is None:\n",
    "                    print(\"Failed to select center. Exiting.\")\n",
    "                    return\n",
    "                # Select the radius of the dial\n",
    "                radius = get_radius(unprocessed_frame.copy(), center, dial_letter)\n",
    "                if radius is None:\n",
    "                    print(\"Failed to select radius. Exiting.\")\n",
    "                    return\n",
    "                if confirm_circle(unprocessed_frame.copy(), center, radius, dial_letter):\n",
    "                    break\n",
    "\n",
    "            # Select the origin and maximum points on the dial\n",
    "            print(f\"Click on the point representing the minimum value for dial {dial_letter}.\")\n",
    "            origin_angle = get_angle_from_click(unprocessed_frame.copy(), center, window_name=f\"Select Minimum Point for Dial {dial_letter}\")\n",
    "            if origin_angle is None:\n",
    "                print(\"Failed to select minimum point. Exiting.\")\n",
    "                return\n",
    "            print(f\"Selected origin angle for dial {dial_letter}: {origin_angle:.2f} degrees\")  # Debugging statement\n",
    "            value_at_origin = get_float_input(\"Enter the value at the origin: \")\n",
    "\n",
    "            print(f\"Click on the point representing the maximum value for dial {dial_letter}.\")\n",
    "            max_angle = get_angle_from_click(unprocessed_frame.copy(), center, window_name=f\"Select Maximum Point for Dial {dial_letter}\")\n",
    "            if max_angle is None:\n",
    "                print(\"Failed to select maximum value point. Exiting.\")\n",
    "                return\n",
    "            print(f\"Selected maximum angle for dial {dial_letter}: {max_angle:.2f} degrees\")  # Debugging statement\n",
    "            value_at_max = get_float_input(\"Enter the value at the maximum position: \")\n",
    "\n",
    "            # Assume clockwise direction\n",
    "            clockwise = True\n",
    "\n",
    "            # Generate segment boxes and map values to each segment\n",
    "            segment_boxes = get_segment_boxes(unprocessed_frame.copy(), center, radius, radius, origin_angle, max_angle, value_at_origin, value_at_max, clockwise)\n",
    "            base_values = map_values_to_segments(segment_boxes, origin_angle, max_angle, value_at_origin, value_at_max, clockwise)\n",
    "\n",
    "            # Store the segment information in the dictionary\n",
    "            segment_info_dict[dial_letter] = (center, radius, radius, radius, origin_angle, max_angle, clockwise, segment_boxes, base_values)\n",
    "\n",
    "        # Save the segment configuration to a JSON file\n",
    "        save_config(segment_info_dict, os.path.join(output_dir_base, \"dial_segment_config.json\"))\n",
    "\n",
    "    # Ask for replicate information\n",
    "    replicate_info = get_replicate_info(dial_letters)\n",
    "\n",
    "    # Process each video and save the results\n",
    "    combined_time = 1  # Initialize the combined time for the entire dataset\n",
    "    for idx, video_path in enumerate(sorted(video_paths)):  # Ensure files are processed in alphanumeric order\n",
    "        video_path = normalize_path(video_path)\n",
    "        base_filename = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        output_excel = os.path.join(output_dir_base, f\"output_data_{base_filename}.xlsx\")\n",
    "        output_dir = os.path.join(output_dir_base, f\"processed_frames_{base_filename}\")\n",
    "\n",
    "        # Process the video and get the data\n",
    "        video_data = process_video(\n",
    "            video_path,\n",
    "            output_excel,\n",
    "            output_dir,\n",
    "            frame_skip,\n",
    "            segment_threshold,\n",
    "            frame_start,\n",
    "            frame_end,\n",
    "            segment_info_dict,\n",
    "            idx,\n",
    "            len(video_paths)\n",
    "        )\n",
    "\n",
    "        # Combine data from all dials for the same frame\n",
    "        frame_data = {}\n",
    "        for dial_letter in dial_letters:\n",
    "            for entry in video_data[dial_letter]:\n",
    "                frame_number = entry[0]\n",
    "                if frame_number not in frame_data:\n",
    "                    frame_data[frame_number] = {\n",
    "                        \"individual_time_s\": frame_number,\n",
    "                        \"video_file\": base_filename,\n",
    "                    }\n",
    "                # Add the data for the specific dial to the current frame\n",
    "                frame_data[frame_number][f\"dial_{dial_letter}_primary\"] = entry[1]\n",
    "\n",
    "        # Append the combined frame data to the list\n",
    "        combined_data.extend(frame_data.values())\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Calculate mean and standard deviation for each group of replicates\n",
    "    for group_name, dials in replicate_info.items():\n",
    "        dial_columns = [f'dial_{dial}_primary' for dial in dials]\n",
    "        combined_df[f'{group_name}_mean'] = combined_df[dial_columns].mean(axis=1)\n",
    "        combined_df[f'{group_name}_std'] = combined_df[dial_columns].std(axis=1)\n",
    "\n",
    "    # Sort combined data by video file name and then by individual time\n",
    "    combined_df = combined_df.sort_values(by=['video_file', 'individual_time_s']).reset_index(drop=True)\n",
    "\n",
    "    # Add combined_time_s, combined_time_m, and combined_time_h\n",
    "    combined_df['combined_time_s'] = range(1, 1 + frame_skip * len(combined_df), frame_skip)\n",
    "    combined_df['combined_time_m'] = combined_df['combined_time_s'] / 60\n",
    "    combined_df['combined_time_h'] = combined_df['combined_time_m'] / 60\n",
    "\n",
    "    # Reorder columns for better readability\n",
    "    columns_order = ['combined_time_s', 'combined_time_m', 'combined_time_h', 'individual_time_s', 'video_file']\n",
    "    for dial_letter in dial_letters:\n",
    "        columns_order.extend([f'dial_{dial_letter}_primary'])\n",
    "    for group_name in replicate_info.keys():\n",
    "        columns_order.extend([f'{group_name}_mean', f'{group_name}_std'])\n",
    "    combined_df = combined_df[columns_order]\n",
    "\n",
    "    # Save combined data to Excel\n",
    "    combined_output_path = os.path.join(output_dir_base, f\"{os.path.basename(output_dir_base)}_combined_output.xlsx\")\n",
    "    with ExcelWriter(combined_output_path) as writer:\n",
    "        combined_df.to_excel(writer, sheet_name='Combined Data', index=False)\n",
    "        print(f\"Combined data saved to {combined_output_path}\")\n",
    "\n",
    "    # Plot combined data for all dials individually\n",
    "    plot_combined_data(combined_df, output_dir_base)\n",
    "\n",
    "    # Plot the mean data for each replicate with 1 SD error bars\n",
    "    plot_replicate_means_with_error(combined_df, replicate_info, output_dir_base)\n",
    "\n",
    "\n",
    "def process_video(video_path, output_excel, output_dir, frame_skip, segment_threshold, frame_start, frame_end, segment_info_dict, idx=0, total_files=1):\n",
    "    video_path = normalize_path(video_path.strip('\"'))  # Normalize the video path to ensure compatibility across different operating systems\n",
    "    output_excel = normalize_path(output_excel.strip('\"'))  # Normalize the output Excel file path\n",
    "    output_dir = normalize_path(output_dir.strip('\"'))  # Normalize the output directory path\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)  # Open the video file using OpenCV\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get the total number of frames in the video\n",
    "    video_data = {dial_letter: [] for dial_letter in segment_info_dict.keys()}  # Initialize a dictionary to store data for each dial\n",
    "    summary_data = []  # List to store summary data\n",
    "\n",
    "    if not os.path.exists(output_dir):  # Check if the output directory exists\n",
    "        os.makedirs(output_dir)  # Create the output directory if it doesn't exist\n",
    "\n",
    "    # Define the debug file path for writing debug information\n",
    "    debug_file_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_debug.txt\")\n",
    "    \n",
    "    with open(debug_file_path, 'w') as debug_file:  # Open the debug file for writing\n",
    "        if frame_start is None:\n",
    "            frame_start = 0  # If no start frame is specified, start from the first frame\n",
    "        if frame_end is None:\n",
    "            frame_end = frame_count  # If no end frame is specified, process until the last frame\n",
    "\n",
    "        frame_start = int(frame_start)\n",
    "        frame_end = int(frame_end)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_start)  # Set the starting frame position\n",
    "        ret, frame = cap.read()  # Read the first frame\n",
    "        if not ret:  # If the frame cannot be read, exit the function\n",
    "            print(\"Failed to read the first frame.\")\n",
    "            cap.release()\n",
    "            return None, []\n",
    "        \n",
    "        # Process frame 0\n",
    "        if frame_start == 0:\n",
    "            processed_frame = remove_red_color(frame)  # Remove purple to orange colors\n",
    "            # Save the processed frame before any binary threshold\n",
    "            pre_threshold_image_path = os.path.join(output_dir, \"frame_0000_pre_threshold.png\")\n",
    "            cv2.imwrite(pre_threshold_image_path, processed_frame)  # Save the image\n",
    "            print(f\"Frame 0 after color removal saved to {pre_threshold_image_path}\")\n",
    "\n",
    "\n",
    "        total_frames_to_process = (frame_end - frame_start) // frame_skip + 1  # Calculate the total number of frames to process\n",
    "\n",
    "        starting_threshold = 255  # Initialize the starting threshold for the first frame\n",
    "\n",
    "        # Loop through frames from start to end with specified skip\n",
    "        for i in range(frame_start, frame_end, frame_skip):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)  # Set the frame position to the current frame\n",
    "            ret, frame = cap.read()  # Read the current frame\n",
    "\n",
    "            if not ret:  # If the frame cannot be read, skip to the next iteration\n",
    "                print(f\"Failed to read frame {i}.\")\n",
    "                continue\n",
    "\n",
    "            frame = remove_red_color(frame)  # Remove red color from the frame before processing\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert the frame to grayscale\n",
    "\n",
    "            # Process each dial\n",
    "            for dial_letter, segment_info in segment_info_dict.items():\n",
    "                center, radius, radius_x, radius_y, origin_angle, max_angle, clockwise, segment_boxes, base_values = segment_info\n",
    "                model_primary = Segments(segment_boxes, base_values)  # Initialize the Segments model\n",
    "\n",
    "                current_threshold = starting_threshold  # Start with the last threshold from the previous frame\n",
    "                ratio_on_off = 0  # Initialize the on/off pixel ratio\n",
    "                previous_threshold = None  # Initialize the previous threshold\n",
    "\n",
    "                best_threshold = None  # Initialize the best threshold\n",
    "                closest_ratio = None  # Initialize the closest ratio\n",
    "\n",
    "                recent_thresholds = []  # List to store recent thresholds for oscillation detection\n",
    "\n",
    "                # Threshold adjustment loop to find the best threshold for segment detection\n",
    "                while True:\n",
    "                    try:\n",
    "                        # Apply binary thresholding to the grayscale frame\n",
    "                        _, binary = cv2.threshold(gray, current_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "                        mask = np.zeros_like(gray)  # Create a mask of the same size as the grayscale image\n",
    "                        cv2.circle(mask, center, radius, 255, -1)  # Draw a circle on the mask\n",
    "\n",
    "                        # Count pixels that are 'on' and 'off' within the mask\n",
    "                        on_pixels = np.sum(binary[mask == 255] == 255)\n",
    "                        off_pixels = np.sum(binary[mask == 255] == 0)\n",
    "                        ratio_on_off = on_pixels / off_pixels if off_pixels > 0 else np.nan  # Calculate the on/off ratio\n",
    "\n",
    "                    except Exception as e:  # Handle exceptions\n",
    "                        print(f\"Error calculating ratio: {e}\")\n",
    "                        ratio_on_off = np.nan\n",
    "\n",
    "                    # Update the best threshold if this ratio is valid and closer to the target range\n",
    "                    if not np.isnan(ratio_on_off):\n",
    "                        if closest_ratio is None or abs(ratio_on_off - 0.015) < abs(closest_ratio - 0.015):\n",
    "                            best_threshold = current_threshold\n",
    "                            closest_ratio = ratio_on_off\n",
    "\n",
    "                        recent_thresholds.append(current_threshold)  # Add the current threshold to the recent thresholds list\n",
    "                        if len(recent_thresholds) > 5:\n",
    "                            recent_thresholds.pop(0)  # Keep the last 5 thresholds for oscillation detection\n",
    "\n",
    "                        # Check for threshold oscillation and pick the best threshold if detected\n",
    "                        if len(recent_thresholds) > 3:\n",
    "                            last_three_thresholds = recent_thresholds[-3:]\n",
    "                            if len(set(last_three_thresholds)) == 1:\n",
    "                                print(f\"Oscillation detected. Picking the best threshold: {best_threshold} with closest ratio: {closest_ratio}\")\n",
    "                                current_threshold = best_threshold\n",
    "                                break\n",
    "\n",
    "                    # Adjust the threshold based on the ratio\n",
    "                    if np.isnan(ratio_on_off) or ratio_on_off > 0.13:\n",
    "                        current_threshold = math.floor(current_threshold * 0.995)  # Decrease threshold slightly\n",
    "                    elif ratio_on_off < 0.1:\n",
    "                        current_threshold = math.ceil(current_threshold * 1.01)  # Increase threshold slightly\n",
    "                    else:\n",
    "                        break  # Exit the loop if the ratio is within an acceptable range\n",
    "\n",
    "                    previous_threshold = current_threshold  # Update the previous threshold\n",
    "\n",
    "                    # If no valid ratio was found, stop adjusting and use the last valid best_threshold\n",
    "                    if best_threshold is None:\n",
    "                        best_threshold = starting_threshold  # Fallback to the last known good threshold or initial threshold\n",
    "\n",
    "                # Handle cases where no valid ratio was found\n",
    "                if closest_ratio is None:\n",
    "                    closest_ratio = \"N/A\"  # If no valid ratio was found, set to \"N/A\"\n",
    "                    print(f\"No valid ratio found, using fallback threshold: {best_threshold}\")\n",
    "\n",
    "                binary_copy = binary.copy()  # Create a copy of the binary image\n",
    "                # Analyze the binary image to detect segments\n",
    "                model_primary.digest(binary_copy, segment_threshold, debug_file, i, current_threshold, write_to_debug=True, calculate_baseline=(i == 0))\n",
    "                number_primary = model_primary.get_num()  # Get the detected number from the model\n",
    "\n",
    "                # Annotate the binary image with detected information\n",
    "                text_ratio = f\"Ratio: {closest_ratio:.4f}\"\n",
    "                text_threshold = f\"Threshold: {current_threshold}\"\n",
    "                font_scale = 3.0\n",
    "                thickness = 6\n",
    "                text_color = (255, 255, 255)\n",
    "\n",
    "                text_position_ratio = (binary_copy.shape[1] - 800, 110)\n",
    "                text_position_threshold = (binary_copy.shape[1] - 800, 220)\n",
    "\n",
    "                # Draw text annotations on the binary image\n",
    "                cv2.putText(binary_copy, text_ratio, text_position_ratio, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness)\n",
    "                cv2.putText(binary_copy, text_threshold, text_position_threshold, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness)\n",
    "                cv2.putText(binary_copy, f\"{number_primary:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness)\n",
    "\n",
    "                # Conditionally save the annotated frame as a PNG file based on user input\n",
    "                if save_images:\n",
    "                    frame_output_path = os.path.join(output_dir, f\"frame_{i:04d}_{dial_letter}.png\")\n",
    "                    cv2.imwrite(frame_output_path, binary_copy)  # Save the annotated frame as a PNG file\n",
    "                    #print(f\"Processed frame saved to {frame_output_path}\")\n",
    "\n",
    "                # Append frame data to video data\n",
    "                video_data[dial_letter].append([\n",
    "                    i,  # Frame Number\n",
    "                    number_primary,  # Detected Number\n",
    "                    current_threshold,  # Binary Threshold\n",
    "                    closest_ratio  # On:Off Ratio\n",
    "                ])\n",
    "\n",
    "                print(f\"Frame {i} | Dial {dial_letter} | Detected Number: {number_primary} (Threshold: {current_threshold})\")\n",
    "\n",
    "                # Store the final threshold used in this iteration to start the next frame\n",
    "                starting_threshold = current_threshold\n",
    "\n",
    "            # Calculate the number of processed frames\n",
    "            frames_processed = (i - frame_start) // frame_skip\n",
    "            # Calculate the percentage of completion\n",
    "            percent_complete = (frames_processed / total_frames_to_process) * 100\n",
    "            print(f\"Now processing {os.path.basename(video_path)}, {idx + 1} of {total_files}. Frame {i} of {frame_count}, {percent_complete:.2f}% complete.\")\n",
    "\n",
    "    cap.release()  # Release the video capture object\n",
    "    cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n",
    "    # Save results to Excel\n",
    "    with ExcelWriter(output_excel) as writer:\n",
    "        for dial_letter in segment_info_dict.keys():\n",
    "            # Specify only the required columns\n",
    "            columns = ['Frame Number', 'Detected Number', 'Binary Threshold', 'On:Off Ratio']\n",
    "            df = pd.DataFrame(video_data[dial_letter], columns=columns)  # Create a DataFrame from video data\n",
    "\n",
    "            # Write DataFrame to Excel\n",
    "            df.to_excel(writer, sheet_name=f'Dial {dial_letter}', index=False)\n",
    "            print(f\"Results saved to {output_excel} in sheet 'Dial {dial_letter}'\")\n",
    "\n",
    "            # Plotting all individual dials for the video on one plot\n",
    "            fig_individual = go.Figure()\n",
    "            for dial_letter in segment_info_dict.keys():\n",
    "                fig_individual.add_trace(go.Scatter(\n",
    "                    x=df['Frame Number'],\n",
    "                    y=df['Detected Number'],\n",
    "                    mode='lines+markers',\n",
    "                    name=f'Dial {dial_letter}'\n",
    "                ))\n",
    "\n",
    "            fig_individual.update_layout(\n",
    "                title=f'Individual Detected Numbers for {os.path.basename(video_path)} - All Dials',\n",
    "                xaxis_title='Frame Number',\n",
    "                yaxis_title='Detected Number',\n",
    "                legend_title='Dials',\n",
    "                template='plotly_white'\n",
    "            )\n",
    "\n",
    "            plot_output_path_individual = os.path.join(output_dir, f\"output_plot_individual_{os.path.basename(video_path)}.html\")\n",
    "            fig_individual.write_html(plot_output_path_individual)  # Save plot to HTML file\n",
    "            print(f\"Individual plot saved to {plot_output_path_individual}\")\n",
    "\n",
    "        # Create a summary DataFrame for any additional summary data (if needed)\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)  # Write summary data to Excel\n",
    "        print(f\"Summary sheet saved to {output_excel}\")\n",
    "\n",
    "    return video_data\n",
    "\n",
    "def plot_combined_data(combined_df, output_dir_base):\n",
    "    \"\"\"\n",
    "    Function to plot combined data for all dials individually.\n",
    "    \"\"\"\n",
    "    # Plotting the combined data using Plotly\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    # Loop over each column that matches the dial data pattern\n",
    "    for dial_letter in combined_df.columns:\n",
    "        # Check if the column name starts with 'dial_' and ends with '_primary'\n",
    "        if dial_letter.startswith('dial_') and dial_letter.endswith('_primary'):\n",
    "            fig_combined.add_trace(go.Scatter(\n",
    "                x=combined_df['combined_time_s'],  # X-axis is the combined time in seconds\n",
    "                y=combined_df[dial_letter],  # Y-axis is the data for this dial\n",
    "                mode='lines+markers',  # Plot both lines and markers\n",
    "                name=dial_letter  # Label for this trace\n",
    "            ))\n",
    "\n",
    "    # Update the layout of the plot to include titles and labels\n",
    "    fig_combined.update_layout(\n",
    "        title='Combined Detected Numbers - All Dials',  # Title of the plot\n",
    "        xaxis_title='Combined Time (s)',  # X-axis label\n",
    "        yaxis_title='Detected Number',  # Y-axis label\n",
    "        legend_title='Legend',  # Legend title\n",
    "        template='plotly_white'  # Use a clean white template for the plot\n",
    "    )\n",
    "\n",
    "    # Show the combined plot\n",
    "    fig_combined.show()\n",
    "\n",
    "    # Define the path where the combined plot will be saved as an HTML file\n",
    "    combined_plot_path = os.path.join(output_dir_base, \"combined_plot_all_dials.html\")\n",
    "    # Save the plot to an HTML file\n",
    "    fig_combined.write_html(combined_plot_path)\n",
    "    print(f\"Combined plot saved to {combined_plot_path}\")\n",
    "\n",
    "\n",
    "def plot_replicate_means_with_error(combined_df, replicate_info, output_dir_base):\n",
    "    \"\"\"\n",
    "    Function to plot replicate means with 1 SD error bars.\n",
    "    \"\"\"\n",
    "    # Create a figure object for the plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Loop over each group of replicates\n",
    "    for group_name in replicate_info.keys():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=combined_df['combined_time_h'],  # X-axis is the combined time in hours\n",
    "            y=combined_df[f'{group_name}_mean'],  # Y-axis is the mean for this group\n",
    "            mode='lines+markers',  # Plot both lines and markers\n",
    "            name=f'{group_name} Mean',  # Label for this trace\n",
    "            error_y=dict(\n",
    "                type='data',  # Error type is data-based\n",
    "                array=combined_df[f'{group_name}_std'],  # Error bars are the standard deviation for this group\n",
    "                visible=True  # Show error bars\n",
    "            )\n",
    "        ))\n",
    "\n",
    "    # Update the layout of the plot to include titles and labels\n",
    "    fig.update_layout(\n",
    "        title='Combined Detected Numbers - All Dials with Replicate Means and Error Bars',  # Title of the plot\n",
    "        xaxis_title='Time (Hours)',  # X-axis label\n",
    "        yaxis_title='Vacuum drawn (inHg)',  # Y-axis label\n",
    "        legend_title='Legend',  # Legend title\n",
    "        template='plotly_white'  # Use a clean white template for the plot\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "    # Define the path where the plot will be saved as an HTML file\n",
    "    plot_output_path = os.path.join(output_dir_base, \"combined_plot_all_dials_with_replicates.html\")\n",
    "    # Save the plot to an HTML file\n",
    "    fig.write_html(plot_output_path)\n",
    "    print(f\"Combined plot saved to {plot_output_path}\")\n",
    "\n",
    "# Inputs\n",
    "video_paths = input(\"Enter video paths separated by spaces: \").split()\n",
    "video_paths = [os.path.normpath(path.replace('\"', '')) for path in video_paths]\n",
    "output_dir_base = os.path.normpath(input(\"Enter the base output directory: \").replace('\"', ''))\n",
    "\n",
    "# Add input to ask the user if they want to save images\n",
    "save_images = input(\"Do you want to save processed frame images? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "frame_skip = 60\n",
    "segment_threshold = 0.2\n",
    "window_size = 400\n",
    "step_angle = 2  # Updated to draw segment boxes every x degrees\n",
    "\n",
    "frame_start_input = input(\"Enter the starting frame number (leave blank to start from the first frame): \")\n",
    "frame_start = int(frame_start_input) if frame_start_input else None\n",
    "frame_end_input = input(\"Enter the ending frame number (leave blank to process until the end): \")\n",
    "frame_end = int(frame_end_input) if frame_end_input else None\n",
    "\n",
    "print(\"Video Paths:\", video_paths)\n",
    "print(\"Output Directory Base:\", output_dir_base)\n",
    "print(\"Frame Skip:\", frame_skip)\n",
    "print(\"Segment Threshold:\", segment_threshold)\n",
    "print(\"Window Size:\", window_size)\n",
    "print(\"Step Angle:\", step_angle)\n",
    "print(\"Frame Start:\", frame_start)\n",
    "print(\"Frame End:\", frame_end)\n",
    "print()\n",
    "\n",
    "process_multiple_videos(video_paths, output_dir_base, frame_skip, segment_threshold, frame_start, frame_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
